{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview ##\n",
    "1. Neuron\n",
    "1. Hidden Layer\n",
    "1. Dataset\n",
    "1. Data Preprocessing\n",
    "1. Penghitungan Loss\n",
    "1. Training Data\n",
    "1. Referensi\n",
    "\n",
    "\n",
    "\n",
    "### Neuron ###\n",
    "\n",
    "Untuk membuat neuron, langkahnya cukup sederhana yaitu hanya dengan memanfaatkan library numpy. Sebagai contoh adalah  \n",
    "![neuron](neuron.png)  \n",
    "*Gambar 1. Model sederhana dari Neuron (Perceptron)*\n",
    "\n",
    "di mana kotak merah adalah inputan, kotak biru adalah bias (B), dan kotak orange adalah fungsi aktivasi (sigmoid) $f(x)$. Dengan ini kita mendapatkan:  \n",
    "$x_1 \\to x_1 + b_1$  \n",
    "$x_2 \\to x_2 + b_2$  \n",
    "\n",
    "Kemudian, semua nilai $x_1$ dan $x_2$ ditambahkan dengan bias, sehingga:\n",
    "\n",
    "$output = (x_1 * b_1) + (x_2 * b_2) + B$ \n",
    "\n",
    "Dengan demikian, nilai $y$ bisa kita peroleh dengan:\n",
    "\n",
    "$y = f(output)$\n",
    "\n",
    "Adapun jika dibuat dalam bentuk kode adalah  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990889488055994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# membuat fungsi sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "    \n",
    "    def __init__(self, bobot, bias):\n",
    "        self.bobot = bobot\n",
    "        self.bias = bias\n",
    "        \n",
    "    def feedforward(self, inputan):\n",
    "        total = np.dot(self.bobot, inputan) + self.bias\n",
    "        return sigmoid(total)\n",
    "    \n",
    "bobot = np.array([0, 1])\n",
    "bias = 4\n",
    "\n",
    "n = Neuron(bobot, bias)\n",
    "\n",
    "x = np.array([2,3])\n",
    "print(n.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di dalam sebuah neuron, terdapat beberapa istilah yaitu bobot, bias, dan fungsi aktivasi. Bobot dalam Neural Network (NN) adalah parameter utama yang berubah. Sedangkan bias adalah parameter tambahan. Nilai bias juga akan berubah seiring terjadinya training. Bias jugalah yang menyebabkan nilai dari fungsi aktivasi berpindah dari kiri / kanan.\n",
    "\n",
    "### Hidden Layer ###\n",
    "\n",
    "![MLP](mlp.png)\n",
    "*Gambar 2. Model NN untuk MLP*\n",
    "\n",
    "Hidden layer adalah layer tambahan yang berada diantara layer input dan layer output. Sebuah NN sederhana, biasanya terdiri atas input layer dan output layer. NN yang sederhana disebut sebagai **perceptron**. Penambahan hidden layer dalan NN, mengubah alur struktur NN, termasuk proses update bobot.  \n",
    "\n",
    "Pada bagian sebelumnya, kita sudah memiliki sebuah model NN dengan dua buah input (node) yaitu $x_1 = 2$ dan $x_2 = 3$. Node pada hidden layer disimbolkan dengan huruf $h$. Kita buat sebuah model NN kita dengan satu layer yang ter dua buah node yaitu $h_1$ dan $h_2$ dan satu layer output dengan satu node $o_1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7216325609518421\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MyNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        bobot = np.array([0,1]) # inisialisasi bobot awal\n",
    "        bias = 0\n",
    "        \n",
    "        self.h1 = Neuron(bobot, bias)\n",
    "        self.h2 = Neuron(bobot, bias)\n",
    "        self.o1 = Neuron(bobot, bias)\n",
    "    \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        \n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        \n",
    "        return out_o1\n",
    "    \n",
    "network = MyNeuralNetwork()\n",
    "x = np.array([2, 3])\n",
    "\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset ### \n",
    "\n",
    "Di praktikum ini, kita akan mengklasifikasikan jenis kelamin seseorang berdasarkan dua parameter yaitu tinggi badan dan berat badan. Kode berikut ini adalah contoh dari datasetnya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Nama  Berat  Tinggi Jk\n",
      "0   Budi     60     175  L\n",
      "1   Sari     45     150  P\n",
      "2  Indri     46     152  P\n",
      "3   Joko     66     174  L\n",
      "4  Emily     47     151  P\n",
      "5  Frank     63     169  L\n",
      "6  Ahmad     69     172  L\n",
      "7   Lusi     46     151  P\n",
      "8  Bagio     67     168  L\n",
      "9   Siti     49     146  P\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('dataset/jenis_kelamin.csv')\n",
    "\n",
    "X = data.iloc[:,1:3] # mengambil variabel independen saja\n",
    "y = data.iloc[:,3] # mengambil variabel dependen / target / output class\n",
    "\n",
    "y = y.astype('category')\n",
    "y = y.cat.codes\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing ###  \n",
    "Dataset kita preproses dengan dua tahap, yaitu normalisasi dan label encoding.\n",
    "\n",
    "#### Normalisasi & Label Encoding ####\n",
    "Di tahap ini, kita menggunakan teknik normalisasi Min Max Scaler pada atribut independen. Sedangkan pada output, kita gunakan label encoding [0, 1] untuk menggantikan jenis kelamin [L, P]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penghitungan Loss ###\n",
    "\n",
    "Sebelum melatih NN, pertama kali kita harus menghitung seberapa bagus model NN yang telah dibuat. Di dalam statistik, ada salah satu teknik yang berfungsi untuk menghitung nilai error (loss), yaitu Mean-Squared Error (MSE). Formula dari MSE adalah:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n}(y_{true} - y_{pred})^2 \n",
    "$$\n",
    "\n",
    "Dengan melihat dataset kita, misalkan kita ambil data si Budi. Kita bisa menghitung nilai MSE-nya, yaitu:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{1} \\sum_{i=1}^{1}(y_t - y_p)^2   \n",
    "$$\n",
    "$$\n",
    "MSE = (y_t - y_p)^2  \n",
    "$$\n",
    "$$\n",
    "MSE = (1 - y_p)^2\n",
    "$$\n",
    "\n",
    "\n",
    "Berikut ini adalah contoh dari kode MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mse_loss(yt, yp):\n",
    "    return ((yt - yp) ** 2).mean()\n",
    "\n",
    "# 0 adalah contoh output dengan jenis kelamin laki-laki\n",
    "# 1 adalah contoh output dengan jenis kelamin perempuan\n",
    "# yt = y \n",
    "# yp = np.array([0, 0, 0, 0])\n",
    "\n",
    "# print(mse_loss(yt, yp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di MSE, kita membandingkan nilai class aktual (yt) dengan nilai class hasil prediksi (yp). Dari perbandingan data contoh, sudah sangat jelas nilai dari $MSE = 0.5$ dikarenakan hanya ada dua class yp yang nilainya berbeda dengan yt. \n",
    "\n",
    "Nilai loss bisa diperoleh dengan cara menuliskan nilai loss sebagai sebuah fungsi terhadap bobot dan bias. Sehingga, loss $L$ diformulasikan dengan:\n",
    "\n",
    "$$ L(b_1, b_2, b_3, b_4, b_5, b_6, B_1, B_2, B_3) $$\n",
    "\n",
    "### Training Data ###\n",
    "\n",
    "Sebenarnya, tujuan utama dari training adalah mencari nilai bobot-bobot dan bias yang paling optimal dengan cara mengubah nilai tersebut secara berkala sehingga nilai dari loss menjadi sangat kecil (mendekati nol). Langkah ini dinamakan sebagai **optimasi parameter** (OP). Ada beberapa teknik OP yang sering digunakan yaitu Stochastic Gradient Descent (SGD) dan ADAM. Dalam praktikum ini, kita akan memakai SGD untuk OP.  \n",
    "\n",
    "Sebelum membahas SGD, mari kita ingat materi tentang **kaidah rantai** di mana:\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial y}{\\partial x} = \\frac{\\partial y}{\\partial u} . \\frac{\\partial u}{\\partial x}\n",
    "$$\n",
    "\n",
    "Perhatikan Gambar 2. Bagaimana dengan nilai $b_1$ maka nilai loss $L$ juga berubah? jawabannya adalah dengan menggunakan turunan parsial $ \\frac{\\partial L}{\\partial b_1}$. \n",
    "\n",
    "Mari kita tulis ulang turunan parsial dari $\\frac{\\partial y_p}{\\partial b_1} $ di mana:  \n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_1} = \\frac{\\partial L}{\\partial y_p} * \\frac{\\partial y_p}{\\partial b_1}\n",
    "$$\n",
    "\n",
    "Kita bisa menghitung $\\frac{\\partial L}{\\partial y_p}$ karena kita sudah menghitung nilai loss di mana nilai $L = MSE$, seperti pada rumus di atas. Maka, yang kita dapatkan adalah:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial y_p} = \\frac{\\partial (1 - y_p)^2}{\\partial y_p} = -2(1 - y_p)\n",
    "$$\n",
    "\n",
    "Jika kita perhatikan pada Gambar 2, node $o_1$ adalah $y_p$ dan nilainya dipengaruhi oleh node $h_1$ dan $h_2$. Maka, kita mempunyai persamaan $y_p$ sebagai berikut:\n",
    "\n",
    "$$\n",
    "y_p = o_1 = f(b_5h_1 + b_6h_2 + B_3)\n",
    "$$\n",
    "\n",
    "di mana $f$ adalah fungsi sigmoid. Demikian pula dengan nilai $b_1$ yang hanya mempengaruhi $h_1$, maka, kita bisa menuliskan:  \n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_p}{\\partial b_1} = \\frac{\\partial y_p}{\\partial h_1} * \\frac{\\partial h_1}{\\partial b_1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_p}{\\partial h_1} = b_5 * f'(b_5h_1 + b_6h_2 + B_3)\n",
    "$$\n",
    "\n",
    "Kalkulasi yang sama juga kita terapkan pada $\\frac{\\partial h_1}{\\partial b_1}$\n",
    "\n",
    "$$\n",
    "h_1 = f(b_1x_1 + b_2x_2 + B_1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial h_1}{\\partial b_1} = x_1 * f'(b_1x_1 + b_2 x_2 + B_1)\n",
    "$$\n",
    "\n",
    "Perlu diketahui bahwa $x_1$ itu adalah berat badan dan $x_2$ adalah tinggi badan. Langkah berikutnya adalah menurunkan fungsi sigmoid: \n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f'(x) = \\frac{e^{-x}}{(1 + e^{-x})^2} = f(x) * (1 - f(x))\n",
    "$$\n",
    "\n",
    "Alhamdulillah, kita telah berhasil menurunkan beberapa fungsi, sehingga kita bisa menghitung:  \n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_1} = \\frac{\\partial L}{\\partial y_p} * \\frac{\\partial y_p}{\\partial h_1} * \\frac{\\partial h_1}{\\partial b_1}\n",
    "$$\n",
    "\n",
    "Proses update bobot-bobot dan bias ini dinamakan dengan **backpropagasi** atau **backpro**. \n",
    "Mari kita langsung terjun ke kode. Kita buat terlebih dulu kode dari turunan sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_sigmoid(x):\n",
    "    fx = sigmoid(x)\n",
    "    \n",
    "    return fx * (1 - fx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita modif ulang model NN kita, yaitu MyNeuralNetwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # generate nilai random untuk bobot-bobot\n",
    "        self.b1 = np.random.normal()\n",
    "        self.b2 = np.random.normal()\n",
    "        self.b3 = np.random.normal()\n",
    "        self.b4 = np.random.normal()\n",
    "        self.b5 = np.random.normal()\n",
    "        self.b6 = np.random.normal()\n",
    "        \n",
    "        self.B1 = np.random.normal()\n",
    "        self.B2 = np.random.normal()\n",
    "        self.B3 = np.random.normal()\n",
    "    \n",
    "    def feedforward(self, x):\n",
    "        h1 = self.b1 * x[0] + self.b2 * x[1] + self.B1\n",
    "        out_h1 = sigmoid(h1)\n",
    "        \n",
    "        h2 = self.b3 * x[0] + self.b4 + x[1] + self.B2\n",
    "        out_h2 = sigmoid(h2)\n",
    "        \n",
    "        o1 = self.b5 * out_h1 + self.b6 * out_h2 + self.B3\n",
    "        \n",
    "        return sigmoid(o1)\n",
    "    \n",
    "    def train(self, data, all_yt, lr = 0.1, epochs = 1000):\n",
    "        \n",
    "        \n",
    "        sbx = []\n",
    "        sby = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            for x, yt in zip(data, all_yt):\n",
    "            \n",
    "                # kalkulasi feedforward\n",
    "                jml_h1 = self.b1 * x[0] + self.b2 * x[1] + self.B1\n",
    "                h1 = sigmoid(jml_h1)\n",
    "\n",
    "                jml_h2 = self.b3 * x[0] + self.b4 * x[1] + self.B2\n",
    "                h2 = sigmoid(jml_h1)\n",
    "\n",
    "                jml_o1 = self.b5 * h1 + self.b6 * h2 + self.B3\n",
    "                o1 = sigmoid(jml_o1)\n",
    "                yp = o1\n",
    "                \n",
    "                # kalkulasi backpro\n",
    "                # neuron o1\n",
    "                d_L_d_yp = -2 * (yt - yp)\n",
    "\n",
    "                d_yp_d_b5 = h1 * d_sigmoid(jml_o1)\n",
    "                d_yp_d_b6 = h2 * d_sigmoid(jml_o1)\n",
    "                d_yp_d_B3 = d_sigmoid(jml_o1)\n",
    "                \n",
    "                d_yp_d_h1 = self.b5 * d_sigmoid(jml_o1)\n",
    "                d_yp_d_h2 = self.b6 * d_sigmoid(jml_o1)\n",
    "            \n",
    "                # neuron h1\n",
    "                d_h1_d_b1 = x[0] * d_sigmoid(jml_h1)\n",
    "                d_h1_d_b2 = x[1] * d_sigmoid(jml_h1)\n",
    "                d_h1_d_B1 = d_sigmoid(jml_h1)\n",
    "                \n",
    "                # neuron h2\n",
    "                d_h2_d_b3 = x[0] * d_sigmoid(jml_h2)\n",
    "                d_h2_d_b4 = x[1] * d_sigmoid(jml_h2)\n",
    "                d_h2_d_B2 = d_sigmoid(jml_h2)\n",
    "                \n",
    "                # mengupdate bobot b dan bias B\n",
    "                self.b1 -= lr * d_L_d_yp * d_yp_d_h1 * d_h1_d_b1\n",
    "                self.b2 -= lr * d_L_d_yp * d_yp_d_h1 * d_h1_d_b2\n",
    "                self.B1 -= lr * d_L_d_yp * d_yp_d_h1 * d_h1_d_B1\n",
    "                \n",
    "                self.b3 -= lr * d_L_d_yp * d_yp_d_h2 * d_h2_d_b3\n",
    "                self.b4 -= lr * d_L_d_yp * d_yp_d_h2 * d_h2_d_b4\n",
    "                self.B2 -= lr * d_L_d_yp * d_yp_d_h2 * d_h2_d_B2\n",
    "                \n",
    "                self.b5 -= lr * d_L_d_yp * d_yp_d_b5 \n",
    "                self.b6 -= lr * d_L_d_yp * d_yp_d_b6 \n",
    "                self.B3 -= lr * d_L_d_yp * d_yp_d_B3\n",
    "                \n",
    "                if epoch % 10 == 0:\n",
    "                    yp = np.apply_along_axis(self.feedforward, 1, data)\n",
    "                    loss = mse_loss(all_yt, yp)\n",
    "                    sbx.append(epoch)\n",
    "                    sby.append(loss)\n",
    "#                     print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n",
    "                \n",
    "        return sbx, sby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_yt = y_train\n",
    "data = X_train\n",
    "\n",
    "network = MyNeuralNetwork()\n",
    "sbx, sby = network.train(data, all_yt, 0.1, 10000)\n",
    "\n",
    "plt.plot(sbx, sby)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita coba memprediksi dengan sampel berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oddy: 0.022\n",
      "Silvi: 0.808\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "oddy = np.array([0.75, 0.793]).reshape(-1,1) # 63 kg, 169 cm\n",
    "\n",
    "silvi = np.array([0.041, 0.172]).reshape(-1,1)  # 46 kg, 151 cm\n",
    "print(\"Oddy: %.3f\" % network.feedforward(oddy)) \n",
    "print(\"Silvi: %.3f\" % network.feedforward(silvi)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referensi ###\n",
    "Modul ini diadaptasi dari artikel milik Victor Zhou yang bisa diakses di [sini](https://victorzhou.com/blog/intro-to-neural-networks/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
